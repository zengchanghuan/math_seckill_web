#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†2003-2018å¹´çš„Markdownæ–‡ä»¶è½¬æ¢ä¸ºJSONæ ¼å¼
ä¿ç•™å›¾ç‰‡ä¿¡æ¯
"""

import json
import os
import re
from pathlib import Path
from typing import List, Dict, Any

def extract_images(content: str) -> tuple:
    """æå–å†…å®¹ä¸­çš„å›¾ç‰‡å¹¶è¿”å›å¤„ç†åçš„å†…å®¹å’Œå›¾ç‰‡åˆ—è¡¨"""
    images = []
    image_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
    
    matches = re.finditer(image_pattern, content)
    for match in matches:
        images.append({
            "alt_text": match.group(1),
            "url": match.group(2),
            "position": "inline"
        })
    
    return content, images

def parse_markdown_file(file_path: Path, year: int) -> Dict[str, Any]:
    """è§£æå•ä¸ªMarkdownæ–‡ä»¶"""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    
    lines = content.split('\n')
    
    sections = []
    current_section = None
    current_question = None
    question_content_lines = []
    in_answer_section = False
    
    # ç”¨äºå­˜å‚¨æ‰€æœ‰é—®é¢˜ï¼Œæ–¹ä¾¿ç­”æ¡ˆåŒ¹é…
    all_questions = {}
    
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        
        # è·³è¿‡æ–‡ä»¶æ ‡é¢˜è¡Œ
        if i < 5 and (line.startswith('#') or not line):
            i += 1
            continue
        
        # æ£€æµ‹ç« èŠ‚æ ‡é¢˜ï¼ˆä¸€ã€äºŒã€ä¸‰ã€å››ç­‰ï¼‰
        section_match = re.match(r'^#?\s*([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)[ã€\.\s]?\s*(.+?)(?:ï¼ˆ|\(|$)', line)
        if section_match:
            # ä¿å­˜ä¸Šä¸€ä¸ªé—®é¢˜
            if current_question and question_content_lines:
                content_str = '\n'.join(question_content_lines).strip()
                content_str, imgs = extract_images(content_str)
                current_question['content'] = content_str
                current_question['images'].extend(imgs)
                question_content_lines = []
            
            # ä¿å­˜ä¸Šä¸€ä¸ªç« èŠ‚
            if current_section and not in_answer_section:
                sections.append(current_section)
            
            section_name = section_match.group(2).strip()
            
            # åˆ¤æ–­æ˜¯å¦è¿›å…¥ç­”æ¡ˆéƒ¨åˆ†
            if 'ç­”æ¡ˆ' in section_name or 'è§£æ' in section_name or 'å‚è€ƒç­”æ¡ˆ' in section_name:
                in_answer_section = True
                i += 1
                continue
            else:
                in_answer_section = False
            
            current_section = {
                "section_number": section_match.group(1),
                "section_name": section_name,
                "questions": []
            }
            current_question = None
            i += 1
            continue
        
        # æ£€æµ‹é¢˜å·
        question_match = re.match(r'^(\d+)[\.ã€\s](.*)$', line)
        if question_match:
            # ä¿å­˜ä¸Šä¸€ä¸ªé—®é¢˜
            if current_question and question_content_lines:
                content_str = '\n'.join(question_content_lines).strip()
                content_str, imgs = extract_images(content_str)
                if in_answer_section:
                    # ç­”æ¡ˆéƒ¨åˆ†
                    q_num = current_question['question_number']
                    if q_num in all_questions:
                        all_questions[q_num]['answer'] = content_str
                else:
                    # é—®é¢˜éƒ¨åˆ†
                    current_question['content'] = content_str
                    current_question['images'].extend(imgs)
                question_content_lines = []
            
            question_num = int(question_match.group(1))
            question_text = question_match.group(2).strip()
            
            if in_answer_section:
                # ç­”æ¡ˆéƒ¨åˆ†
                current_question = {'question_number': question_num}
                if question_text:
                    question_content_lines.append(question_text)
            else:
                # é—®é¢˜éƒ¨åˆ†
                current_question = {
                    "question_number": question_num,
                    "content": "",
                    "answer": "",
                    "images": []
                }
                current_section['questions'].append(current_question)
                all_questions[question_num] = current_question
                if question_text:
                    question_content_lines.append(question_text)
            
            i += 1
            continue
        
        # æ™®é€šå†…å®¹è¡Œ
        if line and current_question:
            question_content_lines.append(line)
        
        i += 1
    
    # ä¿å­˜æœ€åä¸€ä¸ªé—®é¢˜
    if current_question and question_content_lines:
        content_str = '\n'.join(question_content_lines).strip()
        content_str, imgs = extract_images(content_str)
        if in_answer_section:
            q_num = current_question['question_number']
            if q_num in all_questions:
                all_questions[q_num]['answer'] = content_str
        else:
            current_question['content'] = content_str
            current_question['images'].extend(imgs)
    
    # ä¿å­˜æœ€åä¸€ä¸ªç« èŠ‚
    if current_section and not in_answer_section:
        sections.append(current_section)
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_questions = sum(len(section['questions']) for section in sections)
    total_images = sum(
        len(q['images']) 
        for section in sections 
        for q in section['questions']
    )
    
    return {
        "meta": {
            "province": "å¹¿ä¸œçœ",
            "subject": "é«˜ç­‰æ•°å­¦",
            "year": year,
            "exam_type": "ä¸“å‡æœ¬",
            "total_sections": len(sections),
            "total_questions": total_questions,
            "total_images": total_images
        },
        "paper": {
            "year": year,
            "province": "å¹¿ä¸œçœ",
            "subject": "é«˜ç­‰æ•°å­¦",
            "exam_type": "ä¸“å‡æœ¬",
            "sections": sections
        }
    }

def convert_directory():
    """è½¬æ¢æ•´ä¸ªç›®å½•"""
    input_dir = Path("/Users/zengchanghuan/Documents/å¹¿ä¸œä¸“å‡æœ¬çœŸé¢˜/2003-2018")
    output_dir = Path("/Users/zengchanghuan/Desktop/workspace/flutter/math_seckill_web/public/papers")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # è·å–æ‰€æœ‰MDæ–‡ä»¶
    md_files = sorted(input_dir.glob("*.md"))
    
    print(f"ğŸ“‚ æ‰¾åˆ° {len(md_files)} ä¸ªMarkdownæ–‡ä»¶\n")
    
    success_count = 0
    for md_file in md_files:
        # æå–å¹´ä»½
        year_match = re.search(r'(\d{4})å¹´', md_file.name)
        if not year_match:
            print(f"âš ï¸  è·³è¿‡ {md_file.name}ï¼šæ— æ³•æå–å¹´ä»½")
            continue
        
        year = int(year_match.group(1))
        
        try:
            print(f"ğŸ“„ å¤„ç† {year}å¹´...")
            
            # è§£ææ–‡ä»¶
            data = parse_markdown_file(md_file, year)
            
            # ä¿å­˜JSON
            output_file = output_dir / f"å¹¿ä¸œ_é«˜æ•°_{year}.json"
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"   âœ… æˆåŠŸ: {data['meta']['total_questions']}é¢˜, {data['meta']['total_images']}å›¾")
            print(f"   ğŸ’¾ ä¿å­˜è‡³: {output_file.name}\n")
            
            success_count += 1
            
        except Exception as e:
            print(f"   âŒ å¤±è´¥: {e}\n")
    
    print("=" * 60)
    print(f"âœ… è½¬æ¢å®Œæˆï¼æˆåŠŸ: {success_count}/{len(md_files)}")
    print("=" * 60)

if __name__ == '__main__':
    convert_directory()

